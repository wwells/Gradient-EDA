---
title: "EDA - Scheduling Classifier"
author: "Walt Wells, 2017"
output:
  html_document:
    css: custom.css
    highlight: zenburn
    theme: lumen
---

# Environment Prep

```{r, message=F, warning=F}
if (!require('doMC')) install.packages('doMC')
if (!require('dplyr')) install.packages('dplyr')
if (!require('ggplot2')) install.packages('ggplot2')
if (!require('wesanderson')) install.packages('wesanderson')
if (!require('cowplot')) install.packages('cowplot')
if (!require('lubridate')) install.packages('lubridate')
if (!require('Boruta')) install.packages('Boruta')
if (!require('caret')) install.packages('caret')
if (!require('e1071')) install.packages('e1071')
if (!require('tictoc')) install.packages('tictoc')

# setup parallel processing to speed up model training when on GCP
registerDoMC(cores = 4)

# basic plot settings
theme_set(theme_minimal())
theme_update(plot.title = element_text(hjust = 0.5))
```

# Load Data

```{r}
dictionary <- read.csv('data/2017-12-20_HW1_data_dictionary.csv')
appts <- read.csv('data/2017-12-20_HW1_data.csv', stringsAsFactors = T)
```

# Initial Data Prep

```{r}
results <- appts$appt_status
appts$appt_status <- NULL

## Create binary version of outcome variable
binresults <- as.character(results)
binresults[binresults != "Show"] <- "NotServed"
binresults[binresults == "Show"] <- "Served"
binresults <- as.factor(binresults)
```

### Typing

```{r}
nums <- appts[,c(1,5:7,9:12)]
dates <- appts[,c(2:4, 8)]
```

Let's also prepare the date times, including setting up an "hour" variable, and removing the vars for scheduled date and injury date as the important information is better represented in the "weeksfrom" types of variables. 

```{r}
hour <- as.numeric(gsub(":.*", "", dates$scheduletime))
dates$scheduletime <- NULL

dates$scheduleddate <- NULL
dates$injury_date <- NULL
dates$appointment <- as.Date(dates$appointment)

appts <- cbind(nums, dates, hour, results, binresults)

names(appts)[names(appts) == 'scheduledappointment'] <- 'weeksappt'
names(appts)[names(appts) == 'injuryscheduled'] <- 'weeksinjury'

rm(dates, nums, binresults, hour, results)
```

### NA Checker

```{r}
NAcheck <- function(df){
    index <- sapply(df,function(x)sum(is.na(x)))
    newdf <- data.frame(index = names(df),Missing_Values=index)
    newdf[newdf$Missing_Values > 0,]
} 
NAcheck(appts)
```

# EDA

Let's review some of our factor vars.  

```{r}
table(appts$business_line)
table(appts$doctor_specialty)
table(appts$jurisdiction)
```

### EDA: Plot of Service / Service_Type

```{r}
p1 <- ggplot(appts, aes(x=service_type, fill=service_type)) +
    geom_bar() + 
    scale_y_log10() + 
    ylab("Log10 Counts") + 
    xlab("") + 
    theme(axis.text.y=element_blank(),
          axis.ticks.y=element_blank()) + 
    ggtitle("Service Type") +
    scale_fill_manual(values = wes_palette("Zissou", nlevels(appts$service_type), type="continuous")) +
    coord_flip()

p2 <- ggplot(appts, aes(x=service, fill=service)) +
    geom_bar() + 
    scale_y_log10() + 
    ylab("Log10 Counts") + 
    xlab("") + 
    theme(axis.text.y=element_blank(),
          axis.ticks.y=element_blank()) + 
    ggtitle("Service") +
    scale_fill_manual(values = wes_palette("Zissou", nlevels(appts$service), type="continuous")) +
    coord_flip() 
    
p <- plot_grid( p1 + theme(legend.position="none"),
           p2 + theme(legend.position="none"),
           align = 'vh',
           hjust = -1,
           nrow = 1
           )
p

```

### EDA: Histograms - Variable of Interest

```{r}

p1 <- ggplot(data=appts, aes(x=results, fill=results)) + 
    geom_bar() +
    ylab("") + 
    xlab("") + 
    ggtitle("Dependant Variable:  \n All Categories") + 
    scale_fill_manual(values = wes_palette("Darjeeling")) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

p2 <- ggplot(data=appts, aes(x=binresults, fill=binresults)) + 
    geom_bar() +
    ylab("") + 
    xlab("") + 
    ggtitle("Dependant Variable: \n Binary Only") + 
    scale_fill_manual(values = wes_palette("Darjeeling")) +
    theme(axis.text.x = element_text(angle = 90, hjust = 1))

p <- plot_grid( p1 + theme(legend.position="none"),
           p2 + theme(legend.position="none"),
           align = 'vh',
           hjust = -1,
           nrow = 1
           )
p

```

Let's move forward using our binary feature of "Served/NotServed" as our predictor.   That's a lot of cancellations and no-shows!

```{r}
appts$results <- NULL
```

### EDA: Trends over Time

```{r}
df <- appts %>% 
     group_by(appointment, binresults) %>%
     summarise(count=n())

ggplot(df, aes(appointment, count, color=binresults)) + 
    geom_line() +
    ggtitle("Outcome as TimeSeries") 
    
```

Let's add a factor for day of the week since we see a clear pattern in the plot above.  

```{r}
appts$apptdayofweek <- wday(appts$appointment, label=T)
```

### EDA: Plot of Weekday

```{r}
df <- appts %>% 
    group_by(apptdayofweek, binresults) %>%
    summarise(count=n()) %>%
    mutate(proportion = count / sum(count))

p1 <- ggplot(df, aes(apptdayofweek, count, fill = binresults)) +
    geom_line(aes(group=apptdayofweek)) +
    geom_point(aes(color=binresults)) +
    coord_flip() +
    ggtitle("Outcome by \n Count") +
    ylab("") + 
    xlab("")

p2 <- ggplot(df, aes(apptdayofweek, proportion, fill = binresults)) +
    geom_line(aes(group=apptdayofweek)) +
    geom_point(aes(color=binresults)) +
    coord_flip() +
    ggtitle("Outcome by \n Proportion") +
    ylab("") +
    xlab("")

prow <- plot_grid( p1 + theme(legend.position="none"),
           p2 + theme(legend.position="none"),
           align = 'vh',
           hjust = -1,
           nrow = 1
           )

legend_b <- get_legend(p1 + theme(legend.position="bottom"))
p <- plot_grid(prow, legend_b, ncol = 1, rel_heights = c(1, .2))
p
```

Once we are looking at proportions, this doesn't look substantially different from day to day - slightly higher degree of negatives on Mondays.   We could perform additional statistical tests to dive deeper, but for now, let's move on. 

### Categorical:  Combining Levels Helper Function

We can see from our tables of categorical variables and some of the visualizations that we will need to combine a number of levels in order for a classifier to work.   Let's build a helper function to do so under a particular threshold.

```{r}
combineLevels <- function(varname, freq) {
  # combine non-ordinal categorical variables with a frequency under a given threshold
  # 
  # Args:
  #   varname: variable of interest
  #   freq:  replace all vars below this frequency
  #
  # Returns:
  #   newvec:  a vector of factors to replace original categorical variable
  newvec <- as.character(appts[[varname]])
  freq_df <- appts %>%
    group_by(appts[[varname]]) %>% 
    summarise(n=n()) %>%
    mutate(freq=n/sum(n))
  
  combine <- as.character(freq_df[1][freq_df$freq < freq,][[1]])
  
  newvec[newvec %in% combine] <- "Other"
  newvec <- as.factor(newvec)
  return(newvec)
}
```

#### Review and Replace Example

```{r}
freq <- .02 #combine observations below this frequency
table(appts$doctor_specialty)
appts$doctor_specialty <- combineLevels('doctor_specialty', freq)
table(appts$doctor_specialty)
```

#### Review and Replace All

```{r}
appts$business_line <- combineLevels("business_line", freq)
appts$jurisdiction <- combineLevels("jurisdiction", freq)
appts$service <- combineLevels("service", freq)
appts$company_external <- combineLevels("company_external", freq)
appts$service_type <- combineLevels("service_type", freq)
appts$apptdayofweek <- combineLevels("apptdayofweek", freq)
```


# Feature Selection

For our initial explorations, we'll use the Boruta Algorithm to help us find the most important features for our modeling.  https://cran.r-project.org/web/packages/Boruta/Boruta.pdf

## Feature Review using Boruta Algorithm

```{r, cache=TRUE}
set.seed(121)
bor.results <- Boruta(subset(appts, select = -c(binresults)),
                      appts$binresults,
                      maxRuns=101,
                      doTrace=0)
```

### Plotting Boruta Results

```{r}
plot(bor.results, las=2, xlab = '', main='Boruta Algorithm: Feature Importance - Binary', space=1, cex.axis=.6) 
```

### RFE

```{r, cache=TRUE}
set.seed(121)
tic("RFE Selection")
appts$results <- NULL
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(binresults~., data=appts, rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))
toc()
```

### Subset for Modeling

For now, let's use the recommendations above about which features are most important and remove `hour`, `day of the week`, and `appointment` date.  We'll leave in the `company_external` and `doctor_specialty` for now. 

```{r}
# remove features with minimal variance
remove <- nearZeroVar(appts, freqCut = 10, uniqueCut = 10, names=TRUE)
apptssub <- appts[ , setdiff(names(appts), remove)]

# remove other features w/ little impact
apptssub <- subset(apptssub, select = -c(hour, apptdayofweek, appointment))
```

# Modeling

## Split Data

```{r}
set.seed(121)
TrainingDataIndex <- createDataPartition(apptssub$binresults, p=0.80, list = FALSE)
trainingData <- apptssub[TrainingDataIndex,]
testData <- apptssub[-TrainingDataIndex,]
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats=3)
```

## Train and Compare Classifiers

Naive Bayes, SVM, Decision Tree, Random Forest, Neural Nets

### Decision Tree

```{r, cache=TRUE}
tic("Decision Tree Train")
set.seed(121)
DT_Model <- train(binresults ~ ., data = trainingData,
                  method = "C5.0",
                  preProcess = c("scale","center"),
                  trControl = ctrl)
toc()
tic("Decision Tree Predict")
DT_Predictions <- predict(DT_Model, testData)

cmDT <- confusionMatrix(DT_Predictions, testData$binresults)
cmDT
toc()
```

### Random Forest

```{r, cache=TRUE}
tic("Random Forest Train")
set.seed(121)
RF_Model <- train(binresults ~ ., data = trainingData,
                  method = "rf",
                  preProcess = c("scale","center"),
                  trControl = ctrl)
toc()

tic("Random Forest Predict")
RF_Predictions <- predict(RF_Model, testData)

cmRF <- confusionMatrix(RF_Predictions, testData$binresults)
cmRF
toc()
```

### SVM

```{r, cache=TRUE}
tic("SVM Train")
set.seed(121)
SVM_Model <- train(binresults ~ ., data = trainingData,
                 method = "svmPoly",
                 trControl= ctrl,
                 tuneGrid = data.frame(degree = 1,
                                       scale = 1,
                                       C = 1),
                 preProcess = c("pca","scale","center"))
toc()
tic("SVM Predict")
SVM_Predictions <- predict(SVM_Model, testData)

cmSVM <- confusionMatrix(SVM_Predictions, testData$binresults)
cmSVM
toc()
```

### Naive Bayes

```{r, cache=TRUE}
tic("Naive Bayes Train")
set.seed(121)
NB_Model <- train(binresults ~ ., data = trainingData,
                 method = "nb",
                 trControl= ctrl,
                 preProcess = c("scale","center"))
toc()
tic("Naive Bayes Predict")
NB_Predictions <- predict(NB_Model, testData)

cmNB <- confusionMatrix(NB_Predictions, testData$binresults)
cmNB
toc()
```

### Neural Nets

```{r, cache=TRUE}
tic("Neural Nets Train")
set.seed(121)
NN_Model <- train(binresults ~ ., data = trainingData,
                 method = "nnet",
                 trControl= ctrl,
                 preProcess = c("scale","center"))
toc()
tic("Neural Nets Predict")
NN_Predictions <- predict(NN_Model, testData)

cmNN <- confusionMatrix(NN_Predictions, testData$binresults)
cmNN
toc()
```


```{r}
results <- resamples(list(RF=RF_Model, 
                          DT=DT_Model, 
                          SVM=SVM_Model,
                          NB=NB_Model,
                          NN=NN_Model))
summary(results)
bwplot(results)
```

```{r}
importance <- varImp(RF_Model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)
```